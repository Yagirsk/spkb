1. https://www.uni-bamberg.de/fileadmin/xai/studies/theses/2024/Master_Thesis_David_Tafler.pdf - Магистерская диссертация исследует генеративную аугментацию в пространстве эмбеддингов базовых моделей (DINOv2) с помощью CVAE для решения long-tailed learning и приватности; генерирует синтетические эмбеддинги для баланса классов и анонимизации; эксперименты на CIFAR-10/100 и MedMNIST показывают рост точности до 92.72% и высокую приватность (расстояние до оригиналов >0.5); комбинируется с Remix и Balanced Softmax.

2. https://arxiv.org/pdf/2502.18691 - Работа предлагает три техники аугментации для CNN: Pairwise Channel Transfer (обмен каналами), Occlusion (закрытие участков) и Masking (маскирование); тестирование на Caltech-101 с малыми подвыборками (5–30 изображений/класс); предотвращает переобучение, повышая точность на 10–25% по сравнению с базовыми аугментациями (повороты, отражения); лучшие результаты при комбинации всех трёх методов.

3. https://arxiv.org/pdf/2510.20344 - Предлагается DAERNN — алгоритм аугментации для нейросетей с цензурированными (censored) данными; использует RNN для моделирования распределения времени до события; генерирует синтетические цензурированные выборки; тестирование на медицинских датасетах показывает рост AUC на 8–15% и снижение bias в оценке выживаемости; адаптивно учитывает уровень цензурирования.

4. https://arxiv.org/pdf/2405.09591 - Обзор традиционных (геометрические, цветовые) и нейронных (GAN, VAE, диффузии) методов аугментации для изображений, текста и графов; классифицирует по доменам и задачам; обсуждает влияние на обобщение (снижение переобучения на 15–40%); приводит сравнение 50+ методов по эффективности, вычислительной сложности и применимости в low-data режимах.

5. https://www.ijcai.org/proceedings/2024/0625.pdf - Метод неявной семантической аугментации (Implicit Semantic Augmentation) с помощью контрастного обучения и маскирования признаков; повышает устойчивость к шумовым меткам (до 40% шума) и adversarial атакам; тестирование на CIFAR-10/100 и ImageNet; рост robust accuracy на 12–18%; не требует явных семантических аннотаций.

6. https://www.techscience.com/cmc/v85n3/64189/pdf - Обзор аугментации с GAN, VAE и трансфер-лернингом для малых выборок; фокус на медицинских изображениях и IoT-данных; комбинация предобученных моделей с генеративной аугментацией даёт прирост точности на 20–35% при <100 образцах/класс; обсуждает ограничения (mode collapse, вычислительные затраты).

7. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10699340 - Обзор современных методов аугментации изображений (AutoAugment, RandAugment, DiffAugment, GAN-based); сравнение по 12 датасетам компьютерного зрения; нейронные методы превосходят традиционные на 5–15% в low-data; акцент на эффективность в transfer learning и self-supervised режимах.

8. https://thesai.org/Downloads/Volume15No1/Paper_118-Overview_of_Data_Augmentation_Techniques.pdf - Обзор аугментаций для изображений (GAN, MixUp) и временных рядов (DTW-barycentric, SPIRAL); применение в гибридных CNN-LSTM; тестирование на UCR архиве и медицинских сигналах; рост точности на 10–30% при малых данных; включает код и бенчмарки.

9. https://aclanthology.org/2025.cl-1.6.pdf - Оценка синтетических текстовых данных из пользовательского ввода для NLG (T5, LLaMA); включает дедупликацию, фильтрацию по качеству (perplexity, diversity); бенчмарки на GLUE, SuperGLUE; синтетика повышает downstream performance на 3–7%; анализ рисков (bias amplification).

10. https://arxiv.org/pdf/2402.11845 - Самообучение без меток с адаптивной аугментацией (AdaAug); динамически выбирает силу аугментации по уверенности псевдометок; тестирование на CIFAR, ImageNet; рост точности на 5–12% в SSL; повышает устойчивость к шуму и доменным сдвигам; интегрируется с FixMatch и FlexMatch.


11. https://arxiv.org/pdf/2405.08912 - Автоматизированная курация датасетов с помощью эмбеддингов (CLIP/ViT) и кластеризации для удаления шума

12. https://ciam.ru/composites_theses/korolev.pdf?utm_source=chatgpt.com - Разработка алгоритма аугментации обучающих данных для систем компьютерного зрения

13. https://cyberleninka.ru/article/n/metod-augmentatsii-tekstovyh-dannyh-s-sohraneniem-stilya-rechi-i-leksiki-persony - Предложен метод аугментации текста, основанный на синтаксических шаблонах, сохраняющий стиль и лексикон конкретного человека. Метод протестирован на задаче определения эмоционального состояния и показал рост качества моделей для русского и английского языков.

14. https://www.mathnet.ru/links/7514bcc6dfefe622f1309a4220f46705/vkam442.pdf - исследование посвящено нейросетевой модели многомодального распознавания. В работе обсуждаются ограничения в составе обучающих множеств (наборов модальностей), что косвенно затрагивает проблему определения и формирования обучающего множества данных.

15. https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00447-5 - Обширный обзор методов аугментации изображений; включает сравнение эффективности, влияние на переобучение и выбор датасетов.

16. https://arxiv.org/pdf/2205.13445 - Исследование особенностей аугментации для Vision Transformers (ViT). Установлено, что ViT требуют более сильной аугментации (например, MixUp, CutMix) для стабильного обучения

17. https://arxiv.org/pdf/2303.10153 - Смещения фокуса с улучшения архитектур на улучшение данных. Охватывает методы аугментации, фильтрации шумных меток, балансировки и стратегии разделения данных

18. https://arxiv.org/pdf/2103.02852 - ускоренную версию AutoAugment, основанную на дифференцируемом поиске (аналогично DADA). Авторы вводят непрерывное пространство политик аугментации и оптимизируют их с помощью градиентов, что снижает вычислительные затраты на 1–2 порядка

19. https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=9148803&fileOId=9148804 - систематический обзор методов аугментации данных в глубоком обучении, включая классические (повороты, шум) и современные (AutoAugment, MixUp, CutMix). Рассматриваются применения в компьютерном зрении, NLP и медицинской визуализации, а также влияние аугментации на обобщение и устойчивость моделей

20. https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Scale-Aware_Automatic_Augmentation_for_Object_Detection_CVPR_2021_paper.pdf - метод автоматической аугментации, адаптированный специально для задач обнаружения объектов (object detection). В отличие от подходов для классификации, он учитывает масштаб объектов и применяет разные политики аугментации к разным уровням пирамиды признаков

21. https://arxiv.org/pdf/2505.12705v1 - 4-этапный пайплайн для масштабируемого обучения роботов с использованием синтетических данных

22. https://www.sciencedirect.com/science/article/pii/S2590005622000911?utm_source=chatgpt.com - Увеличение объёма данных: подробный обзор современных подходов

23. https://link.springer.com/article/10.1007/s10115-023-01853-2?utm_source=chatgpt.com - Обзор автоматизированных алгоритмов увеличения объёма данных для задач классификации изображений на основе глубокого обучения

24. https://link.springer.com/article/10.1007/s11063-025-11747-9?utm_source=chatgpt.com - Исследование расширения данных при обобщении предметной области

25. https://papers.neurips.cc/paper_files/paper/2022/file/8a1c4a54d73728d4d61701e320687c6d-Paper-Conference.pdf?utm_source=chatgpt.com - Состязательное автодополнение с сохранением меток: подход, основанный на принципе обучения представлению

26. https://arxiv.org/pdf/2111.12427 - Проблемы состязательного улучшения изображений

27. https://www.sciencedirect.com/science/article/pii/S0010482524001021?utm_source=chatgpt.com - Автоматическое увеличение объёма данных для улучшения обобщения результатов глубокого обучения при гистопатологическом исследовании с окраской гематоксилином и эозином

28. https://aclanthology.org/2022.emnlp-main.520.pdf?utm_source=chatgpt.com - Дифференцируемое увеличение объёма данных для контрастивного обучения представлению предложений

29. https://pmc.ncbi.nlm.nih.gov/articles/PMC9001823/?utm_source=chatgpt.com - Увеличение объёма данных при обработке естественного языка: новый подход к генерации текста для классификаторов длинных и коротких текстов

30. https://arxiv.org/html/2501.18845v1?utm_source=chatgpt.com - Расширение текстовых данных для больших языковых моделей: подробный обзор методов, проблем и возможностей

31. https://dl.acm.org/doi/abs/10.1109/TASLP.2024.3402049?utm_source=chatgpt.com - Автоматическое расширение данных для классификации аудио

32. https://www.sciencedirect.com/science/article/pii/S0167639323000778?utm_source=chatgpt.com - Расширение данных для разделения речи

33. https://dl.acm.org/doi/10.1145/3732282?utm_source=chatgpt.com - Увеличение объёма данных на графиках: технический обзор

34. https://arxiv.org/html/2510.09129v1?utm_source=chatgpt.com - Генеративное увеличение объёма данных в графическом контрастивном обучении для рекомендаций

35. https://www.ijcai.org/proceedings/2021/0631.pdf?utm_source=chatgpt.com - Увеличение объёма данных временных рядов для глубокого обучения: обзор

36. https://www.sciencedirect.com/science/article/pii/S001048252201099X?utm_source=chatgpt.com - Увеличение объёма данных для медицинской визуализации: систематический обзор литературы

37. https://pmc.ncbi.nlm.nih.gov/articles/PMC10027281/?utm_source=chatgpt.com - Увеличение объёма медицинских изображений: методы, сравнения и интерпретации

38. https://www.mdpi.com/2076-3417/14/19/9030?utm_source=chatgpt.com - Применение глубоких генеративных нейронных сетей для увеличения объёма данных потребительских опросов при небольшом размере выборки
