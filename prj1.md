1. https://www.uni-bamberg.de/fileadmin/xai/studies/theses/2024/Master_Thesis_David_Tafler.pdf - Магистерская диссертация исследует генеративную аугментацию в пространстве эмбеддингов базовых моделей (DINOv2) с помощью CVAE для решения long-tailed learning и приватности; генерирует синтетические эмбеддинги для баланса классов и анонимизации; эксперименты на CIFAR-10/100 и MedMNIST показывают рост точности до 92.72% и высокую приватность (расстояние до оригиналов >0.5); комбинируется с Remix и Balanced Softmax.

2. https://arxiv.org/pdf/2502.18691 - Работа предлагает три техники аугментации для CNN: Pairwise Channel Transfer (обмен каналами), Occlusion (закрытие участков) и Masking (маскирование); тестирование на Caltech-101 с малыми подвыборками (5–30 изображений/класс); предотвращает переобучение, повышая точность на 10–25% по сравнению с базовыми аугментациями (повороты, отражения); лучшие результаты при комбинации всех трёх методов.

3. https://arxiv.org/pdf/2510.20344 - Предлагается DAERNN — алгоритм аугментации для нейросетей с цензурированными (censored) данными; использует RNN для моделирования распределения времени до события; генерирует синтетические цензурированные выборки; тестирование на медицинских датасетах показывает рост AUC на 8–15% и снижение bias в оценке выживаемости; адаптивно учитывает уровень цензурирования.

4. https://arxiv.org/pdf/2405.09591 - Обзор традиционных (геометрические, цветовые) и нейронных (GAN, VAE, диффузии) методов аугментации для изображений, текста и графов; классифицирует по доменам и задачам; обсуждает влияние на обобщение (снижение переобучения на 15–40%); приводит сравнение 50+ методов по эффективности, вычислительной сложности и применимости в low-data режимах.

5. https://www.ijcai.org/proceedings/2024/0625.pdf - Метод неявной семантической аугментации (Implicit Semantic Augmentation) с помощью контрастного обучения и маскирования признаков; повышает устойчивость к шумовым меткам (до 40% шума) и adversarial атакам; тестирование на CIFAR-10/100 и ImageNet; рост robust accuracy на 12–18%; не требует явных семантических аннотаций.

6. https://www.techscience.com/cmc/v85n3/64189/pdf - Обзор аугментации с GAN, VAE и трансфер-лернингом для малых выборок; фокус на медицинских изображениях и IoT-данных; комбинация предобученных моделей с генеративной аугментацией даёт прирост точности на 20–35% при <100 образцах/класс; обсуждает ограничения (mode collapse, вычислительные затраты).

7. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10699340 - Обзор современных методов аугментации изображений (AutoAugment, RandAugment, DiffAugment, GAN-based); сравнение по 12 датасетам компьютерного зрения; нейронные методы превосходят традиционные на 5–15% в low-data; акцент на эффективность в transfer learning и self-supervised режимах.

8. https://thesai.org/Downloads/Volume15No1/Paper_118-Overview_of_Data_Augmentation_Techniques.pdf - Обзор аугментаций для изображений (GAN, MixUp) и временных рядов (DTW-barycentric, SPIRAL); применение в гибридных CNN-LSTM; тестирование на UCR архиве и медицинских сигналах; рост точности на 10–30% при малых данных; включает код и бенчмарки.

9. https://aclanthology.org/2025.cl-1.6.pdf - Оценка синтетических текстовых данных из пользовательского ввода для NLG (T5, LLaMA); включает дедупликацию, фильтрацию по качеству (perplexity, diversity); бенчмарки на GLUE, SuperGLUE; синтетика повышает downstream performance на 3–7%; анализ рисков (bias amplification).

10. https://arxiv.org/pdf/2402.11845 - Самообучение без меток с адаптивной аугментацией (AdaAug); динамически выбирает силу аугментации по уверенности псевдометок; тестирование на CIFAR, ImageNet; рост точности на 5–12% в SSL; повышает устойчивость к шуму и доменным сдвигам; интегрируется с FixMatch и FlexMatch.

11. https://arxiv.org/pdf/2405.08912 – Автоматизированная курация датасетов с помощью эмбеддингов (CLIP/ViT) и кластеризации: предложен метод группировки данных в многомодальном признаковом пространстве для удаления шумовых и дублирующихся примеров и повышения качества обучающей выборки.

12. https://ciam.ru/composites_theses/korolev.pdf – Разработка алгоритма аугментации обучающих данных для систем компьютерного зрения: описан алгоритм, комбинирующий геометрические и цветовые преобразования, а также синтез изображений в разных условиях, что улучшает устойчивость моделей при малых данных.

13. https://cyberleninka.ru/article/n/metod-augmentatsii-tekstovyh-dannyh-s-sohraneniem-stilya-rechi-i-leksiki-persony – Метод аугментации текстовых данных с сохранением стиля речи и лексики персоны: используется синтаксико-семантические шаблоны для генерации параллельных текстов с оригинальным стилем, проверен на задачах распознавания эмоций для русского и английского.

14. https://www.mathnet.ru/links/7514bcc6dfefe622f1309a4220f46705/vkam442.pdf – Исследование нейросетевой модели многомодального распознавания: рассматриваются ограничения в составе обучающих множеств (количество и тип модальностей), анализируется влияние композиции модальностей на обобщение модели.

15. https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00447-5 – Обзор методов аугментации изображений: охватываются классические (повороты, изменение цвета) и современные (MixUp, CutMix и др.) техники, рассматривается их влияние на переобучение, выбор датасетов и устойчивость моделей.

16. https://arxiv.org/pdf/2205.13445 – Исследование особенностей аугментации для Vision Transformers (ViT): показано, что ViT требуют более интенсивной и разнообразной аугментации (например, MixUp, CutMix, RandAugment) для стабильного обучения и лучшего обобщения.

17. https://arxiv.org/pdf/2303.10153 – Смещение фокуса с улучшения архитектур на улучшение данных: рассматриваются методы улучшения качества данных (аугментация, фильтрация шумных меток, балансировка классов, стратегия разделения выборки) как ключ к повышению эффективности моделей.

18. https://arxiv.org/pdf/2103.02852 – Ускоренная версия AutoAugment: введён дифференцируемый поиск политик аугментации, оптимизация непрерывного пространства параметров аугментации с помощью градиентов, что снижает вычислительные затраты и ускоряет подбор эффективных стратегий.

19. https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=9148803&fileOId=9148804 – Систематический обзор методов аугментации данных в глубоком обучении: объединены классические и современные техники (AutoAugment, MixUp, CutMix), применительно к компьютерному зрению, NLP и медицинской визуализации, рассмотрено влияние на обобщение и устойчивость.

20. https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Scale-Aware_Automatic_Augmentation_for_Object_Detection_CVPR_2021_paper.pdf - Метод автоматической аугментации, адаптированный специально для задач обнаружения объектов: учитывается масштаб объектов и уровни пирамиды признаков, разные политики аугментации применяются к разным уровням, что повышает точность детекторов.

21. https://arxiv.org/pdf/2505.12705v1 - 4-этапный пайплайн для масштабируемого обучения роботов с использованием синтетических данных

22. https://www.sciencedirect.com/science/article/pii/S2590005622000911?utm_source=chatgpt.com - Увеличение объёма данных: подробный обзор современных подходов

23. https://link.springer.com/article/10.1007/s10115-023-01853-2?utm_source=chatgpt.com - Обзор автоматизированных алгоритмов увеличения объёма данных для задач классификации изображений на основе глубокого обучения

24. https://link.springer.com/article/10.1007/s11063-025-11747-9?utm_source=chatgpt.com - Исследование расширения данных при обобщении предметной области

25. https://papers.neurips.cc/paper_files/paper/2022/file/8a1c4a54d73728d4d61701e320687c6d-Paper-Conference.pdf?utm_source=chatgpt.com - Состязательное автодополнение с сохранением меток: подход, основанный на принципе обучения представлению

26. https://arxiv.org/pdf/2111.12427 - Проблемы состязательного улучшения изображений

27. https://www.sciencedirect.com/science/article/pii/S0010482524001021?utm_source=chatgpt.com - Автоматическое увеличение объёма данных для улучшения обобщения результатов глубокого обучения при гистопатологическом исследовании с окраской гематоксилином и эозином

28. https://aclanthology.org/2022.emnlp-main.520.pdf?utm_source=chatgpt.com - Дифференцируемое увеличение объёма данных для контрастивного обучения представлению предложений

29. https://pmc.ncbi.nlm.nih.gov/articles/PMC9001823/?utm_source=chatgpt.com - Увеличение объёма данных при обработке естественного языка: новый подход к генерации текста для классификаторов длинных и коротких текстов

30. https://arxiv.org/html/2501.18845v1?utm_source=chatgpt.com - Расширение текстовых данных для больших языковых моделей: подробный обзор методов, проблем и возможностей

31. https://dl.acm.org/doi/abs/10.1109/TASLP.2024.3402049?utm_source=chatgpt.com - Автоматическое расширение данных для классификации аудио

32. https://www.sciencedirect.com/science/article/pii/S0167639323000778?utm_source=chatgpt.com - Расширение данных для разделения речи

33. https://dl.acm.org/doi/10.1145/3732282?utm_source=chatgpt.com - Увеличение объёма данных на графиках: технический обзор

34. https://arxiv.org/html/2510.09129v1?utm_source=chatgpt.com - Генеративное увеличение объёма данных в графическом контрастивном обучении для рекомендаций

35. https://www.ijcai.org/proceedings/2021/0631.pdf?utm_source=chatgpt.com - Увеличение объёма данных временных рядов для глубокого обучения: обзор

36. https://www.sciencedirect.com/science/article/pii/S001048252201099X?utm_source=chatgpt.com - Увеличение объёма данных для медицинской визуализации: систематический обзор литературы

37. https://pmc.ncbi.nlm.nih.gov/articles/PMC10027281/?utm_source=chatgpt.com - Увеличение объёма медицинских изображений: методы, сравнения и интерпретации

38. https://www.mdpi.com/2076-3417/14/19/9030?utm_source=chatgpt.com - Применение глубоких генеративных нейронных сетей для увеличения объёма данных потребительских опросов при небольшом размере выборки
